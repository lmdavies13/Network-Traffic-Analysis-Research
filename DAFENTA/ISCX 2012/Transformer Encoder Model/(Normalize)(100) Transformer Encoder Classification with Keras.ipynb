{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"T4","authorship_tag":"ABX9TyNCz72Ttcxd5M+Ne9Lxh6mn"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["import tensorflow as tf\n","print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qoWgrBjcZeo8","executionInfo":{"status":"ok","timestamp":1721572704349,"user_tz":240,"elapsed":4224,"user":{"displayName":"Liam Davies","userId":"11304128203820935965"}},"outputId":"9fa58942-8e2d-4348-ac57-de0c24d2d8a6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Num GPUs Available:  1\n"]}]},{"cell_type":"code","source":["import tensorflow as tf\n","\n","# Restrict TensorFlow to only use the first GPU\n","gpus = tf.config.experimental.list_physical_devices('GPU')\n","if gpus:\n","    try:\n","        # Restrict TensorFlow to only use the first GPU\n","        tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n","\n","        # Optional: Set memory growth to prevent TensorFlow from reserving all GPU memory\n","        tf.config.experimental.set_memory_growth(gpus[0], True)\n","\n","        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n","        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n","    except RuntimeError as e:\n","        # Visible devices must be set before GPUs have been initialized\n","        print(e)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AfWv7CkuZgUf","executionInfo":{"status":"ok","timestamp":1721572705748,"user_tz":240,"elapsed":178,"user":{"displayName":"Liam Davies","userId":"11304128203820935965"}},"outputId":"b9040a7e-aea4-45ed-f480-f9e343067efc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1 Physical GPUs, 1 Logical GPUs\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1JNuBWS6bFXF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1721572722430,"user_tz":240,"elapsed":15254,"user":{"displayName":"Liam Davies","userId":"11304128203820935965"}},"outputId":"222e7fe1-9a49-4bfd-a750-02ba643c3784"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive') # for google colab to access google drive"]},{"cell_type":"code","source":["import xml.etree.ElementTree as ET\n","import os\n","import pandas as pd\n","from sklearn.utils import shuffle\n","import calendar\n","from sklearn.preprocessing import StandardScaler\n","import numpy as np\n","\n","# Path to your XML files\n","xml_folder = '/content/drive/My Drive/Colab Notebooks/Independent Study/Data/xml'\n","\n","# List all XML files in the directory\n","xml_files = [f for f in os.listdir(xml_folder) if f.endswith('.xml')]\n","\n","# Initialize an empty list to store data from all XML files\n","all_data = []\n","\n","# Loop through each file in the XML directory\n","for file_name in xml_files:\n","    file_path = os.path.join(xml_folder, file_name)\n","    try:\n","        tree = ET.parse(file_path)\n","        root = tree.getroot()\n","\n","        # Extract data from each <TestbedMonJun14Flows> element (adjust tag as needed)\n","        for flow in root.findall('./*'):  # Check if this tag needs to be adjusted\n","            flow_data = {\n","                'appName': flow.find('appName').text if flow.find('appName') is not None else None,\n","                'totalSourceBytes': flow.find('totalSourceBytes').text if flow.find('totalSourceBytes') is not None else None,\n","                'totalDestinationBytes': flow.find('totalDestinationBytes').text if flow.find('totalDestinationBytes') is not None else None,\n","                'totalSourcePackets': flow.find('totalSourcePackets').text if flow.find('totalSourcePackets') is not None else None,\n","                'direction': flow.find('direction').text if flow.find('direction') is not None else None,\n","                'source': flow.find('source').text if flow.find('source') is not None else None,\n","                'protocolName': flow.find('protocolName').text if flow.find('protocolName') is not None else None,\n","                'sourcePort': flow.find('sourcePort').text if flow.find('sourcePort') is not None else None,\n","                'destination': flow.find('destination').text if flow.find('destination') is not None else None,\n","                'destinationPort': flow.find('destinationPort').text if flow.find('destinationPort') is not None else None,\n","                'startDateTime': flow.find('startDateTime').text if flow.find('startDateTime') is not None else None,\n","                'stopDateTime': flow.find('stopDateTime').text if flow.find('stopDateTime') is not None else None,\n","                'Tag': flow.find('Tag').text if flow.find('Tag') is not None else None\n","            }\n","            all_data.append(flow_data)\n","    except ET.ParseError as pe:\n","        print(f\"Error parsing {file_name}: {pe}\")\n","\n","# Convert list to DataFrame\n","df = pd.DataFrame(all_data)\n","\n","# Display the DataFrame\n","print(df.head())\n","\n","def create_balanced_batches(df, batch_size=100, min_attacks=4):\n","    # Separate attack and normal instances\n","    attacks = df[df['Tag'] == 'Attack']\n","    normals = df[df['Tag'] == 'Normal']\n","\n","    # Shuffle both datasets\n","    attacks = shuffle(attacks)\n","    normals = shuffle(normals)\n","\n","    batches = []\n","    num_batches = len(df) // batch_size\n","\n","    for _ in range(num_batches):\n","        if len(attacks) >= min_attacks and len(normals) >= (batch_size - min_attacks):\n","            # Take min_attacks from attacks and fill the rest with normals\n","            batch = pd.concat([\n","                attacks.iloc[:min_attacks],\n","                normals.iloc[:(batch_size - min_attacks)]\n","            ])\n","            # Shuffle the batch to mix attacks and normals\n","            batch = shuffle(batch)\n","            batches.append(batch)\n","\n","            # Remove selected samples\n","            attacks = attacks.iloc[min_attacks:]\n","            normals = normals.iloc[batch_size - min_attacks:]\n","        else:\n","            break  # Break if there aren't enough samples to fill a batch as specified\n","\n","    # Add remaining samples to a final batch if not empty\n","    if not attacks.empty or not normals.empty:\n","        remaining_batch = pd.concat([attacks, normals])\n","        remaining_batch = shuffle(remaining_batch)\n","        batches.append(remaining_batch)\n","\n","    # Concatenate all batches back into a single DataFrame\n","    new_df = pd.concat(batches).reset_index(drop=True)\n","    return new_df\n","\n","# Assuming df is your original DataFrame\n","new_df = create_balanced_batches(df)\n","\n","# See how many duplicate entries there are in new_df\n","duplicates = new_df.duplicated().sum()\n","original_len = len(new_df)\n","print(f\"Number of duplicate entries: {duplicates}\")\n","print(f\"Original DataFrame length: {original_len}\")\n","print(original_len - duplicates)\n","\n","# Drop the duplicates\n","new_df = new_df.drop_duplicates()\n","print(new_df.shape)\n","\n","# Calculate the correlation matrix as you have already done\n","tag_mapping = {'Normal': 0, 'Attack': 1}\n","new_df['Tag'] = new_df['Tag'].map(tag_mapping)\n","\n","# Function to convert numeric month and weekday to names\n","def process_LLM_datetime(df):\n","    df = df.copy()  # Create a copy of the DataFrame to avoid modifying the original\n","    to_check = ['month', 'weekday']\n","    for col in to_check:\n","        if col == 'month':\n","            df[col] = df[col].apply(lambda x: calendar.month_name[x])\n","        elif col == 'weekday':\n","            df[col] = df[col].apply(lambda x: calendar.day_name[x])\n","    return df\n","\n","# Convert to datetime if not already done\n","new_df['startDateTime'] = pd.to_datetime(new_df['startDateTime'])\n","new_df['stopDateTime'] = pd.to_datetime(new_df['stopDateTime'])\n","\n","# Extract date and time components from startDateTime\n","new_df['year'] = new_df['startDateTime'].dt.year\n","new_df['month'] = new_df['startDateTime'].dt.month\n","new_df['day'] = new_df['startDateTime'].dt.day\n","new_df['weekday'] = new_df['startDateTime'].dt.weekday\n","new_df['dayofyear'] = new_df['startDateTime'].dt.dayofyear\n","new_df['hour'] = new_df['startDateTime'].dt.hour\n","new_df['minute'] = new_df['startDateTime'].dt.minute\n","new_df['second'] = new_df['startDateTime'].dt.second\n","\n","# Calculate duration in seconds\n","new_df['duration_seconds'] = (new_df['stopDateTime'] - new_df['startDateTime']).dt.total_seconds()\n","\n","# Remove start and stop features\n","new_df = new_df.drop(['startDateTime', 'stopDateTime'], axis=1)\n","\n","# Create a copy for LLM processing\n","df_llm = new_df.copy()\n","\n","# Apply the process_LLM_datetime function to the df_llm copy\n","df_llm = process_LLM_datetime(df_llm)\n","\n","print(\"\\nLLM Processed DataFrame (df_llm):\")\n","print(df_llm.head())\n","\n","x = df_llm.drop('Tag', axis=1)\n","y = df_llm['Tag']\n","\n","# Specify columns to normalize\n","columns_to_normalize = ['totalSourceBytes', 'totalDestinationBytes', 'totalSourcePackets', 'duration_seconds']\n","\n","# Use StandardScaler to normalize specified columns\n","scaler = StandardScaler()\n","x[columns_to_normalize] = scaler.fit_transform(x[columns_to_normalize])\n","\n","# Helper function to convert a data row to textual format\n","def textualize(X):\n","    textual_data = []\n","    for index, row in enumerate(X.values):\n","        row_textual = [f\"{col}: {val}\" for col, val in zip(X.columns, row)]\n","        textual_data.append(' '.join(row_textual))\n","    return textual_data\n","\n","x_textual = textualize(x)\n","\n","print(x_textual[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Sf7JpcUxbQgs","executionInfo":{"status":"ok","timestamp":1721574308352,"user_tz":240,"elapsed":258813,"user":{"displayName":"Liam Davies","userId":"11304128203820935965"}},"outputId":"41b53742-91ea-4ef4-be1c-cf9ce35d1d9e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Error parsing TestbedThuJun17-1Flows.xml: not well-formed (invalid token): line 3135760, column 209\n","             appName totalSourceBytes totalDestinationBytes  \\\n","0        Unknown_UDP            16076                     0   \n","1  HTTPImageTransfer              384                     0   \n","2                DNS              171                   642   \n","3  HTTPImageTransfer              384                     0   \n","4  HTTPImageTransfer              186                   128   \n","\n","  totalSourcePackets direction         source protocolName sourcePort  \\\n","0                178       L2R  192.168.5.122       udp_ip       5353   \n","1                  6       L2R  192.168.2.111       tcp_ip       4435   \n","2                  2       L2L  192.168.4.119       udp_ip       4428   \n","3                  6       L2R  192.168.4.119       tcp_ip       3639   \n","4                  2       L2R  192.168.4.119       tcp_ip       3641   \n","\n","       destination destinationPort        startDateTime         stopDateTime  \\\n","0      224.0.0.251            5353  2010-06-13T23:57:19  2010-06-14T00:11:23   \n","1  206.217.198.186              80  2010-06-13T23:58:23  2010-06-14T00:01:24   \n","2    192.168.5.122              53  2010-06-13T23:58:31  2010-06-13T23:59:25   \n","3   219.94.203.105              80  2010-06-13T23:58:31  2010-06-14T00:00:58   \n","4     98.137.80.50              80  2010-06-13T23:58:31  2010-06-13T23:59:26   \n","\n","      Tag  \n","0  Normal  \n","1  Normal  \n","2  Normal  \n","3  Normal  \n","4  Normal  \n","Number of duplicate entries: 138889\n","Original DataFrame length: 1885519\n","1746630\n","(1746630, 13)\n","\n","LLM Processed DataFrame (df_llm):\n","             appName totalSourceBytes totalDestinationBytes  \\\n","0  HTTPImageTransfer             1234                 27469   \n","1  HTTPImageTransfer              464                  2946   \n","2        Unknown_UDP              312                     0   \n","3                DNS              108                   288   \n","4                DNS              537                   928   \n","\n","  totalSourcePackets direction         source protocolName sourcePort  \\\n","0                 17       L2R  192.168.4.119       tcp_ip       4981   \n","1                  6       L2R  192.168.2.109       tcp_ip       2835   \n","2                  2       L2L  192.168.1.101       udp_ip      17500   \n","3                  1       L2R  192.168.5.122       udp_ip      58688   \n","4                  6       L2R  192.168.5.122       udp_ip      54352   \n","\n","     destination destinationPort  Tag  year month  day   weekday  dayofyear  \\\n","0   125.6.172.16              80    0  2010  June   15   Tuesday        166   \n","1   95.211.98.14              80    0  2010  June   15   Tuesday        166   \n","2  192.168.1.255           17500    0  2010  June   17  Thursday        168   \n","3   198.164.30.2              53    0  2010  June   15   Tuesday        166   \n","4   198.164.30.2              53    0  2010  June   12  Saturday        163   \n","\n","   hour  minute  second  duration_seconds  \n","0    19       6      16              10.0  \n","1     9      48      39               1.0  \n","2    10      19      47           12111.0  \n","3    16      44       6               1.0  \n","4     7      38      53               1.0  \n","appName: HTTPImageTransfer totalSourceBytes: -0.0017248478313302274 totalDestinationBytes: -0.006610340768285339 totalSourcePackets: -0.004750313749869765 direction: L2R source: 192.168.4.119 protocolName: tcp_ip sourcePort: 4981 destination: 125.6.172.16 destinationPort: 80 year: 2010 month: June day: 15 weekday: Tuesday dayofyear: 166 hour: 19 minute: 6 second: 16 duration_seconds: -0.06802028462212081\n"]}]},{"cell_type":"code","source":["# columns to normalize\n","# totalSOurceBytes, TotalDestinationBytes, totalSOurceBytes, duration_seconds"],"metadata":{"id":"8UdW39jyywOV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(x_textual[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E9hYD48qk0V9","executionInfo":{"status":"ok","timestamp":1721573692116,"user_tz":240,"elapsed":195,"user":{"displayName":"Liam Davies","userId":"11304128203820935965"}},"outputId":"bc6fb46e-929b-4384-cd1b-026afe10fa2b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["appName: DNS totalSourceBytes: 93 totalDestinationBytes: 259 totalSourcePackets: 1 direction: L2R source: 192.168.5.122 protocolName: udp_ip sourcePort: 32524 destination: 198.164.30.2 destinationPort: 53 year: 0.0 month: June day: 0.6878656736573798 weekday: Wednesday dayofyear: 0.6878656736573903 hour: -0.3664248069871792 minute: -1.3651934809988238 second: -0.22107035975083586 duration_seconds: -0.08136224594522481\n"]}]},{"cell_type":"code","source":["# Tokenize and process the dataset\n","def preprocess_text(texts):\n","    # Extract numeric values and replace them with [NUM] token\n","    numeric_values = []\n","    processed_texts = []\n","    for text in texts:\n","        tokens = text.split()\n","        processed_tokens = []\n","        for token in tokens:\n","            try:\n","                value = float(token)\n","                processed_tokens.append(\"[NUM]\")\n","                numeric_values.append(value)\n","            except ValueError:\n","                processed_tokens.append(token)\n","        processed_texts.append(\" \".join(processed_tokens))\n","    return processed_texts, numeric_values\n","\n","\n","processed_texts, numeric_values = preprocess_text(x_textual)\n"],"metadata":{"id":"k23t4saD9HVf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(processed_texts[0])\n","print(numeric_values[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zXOSE7wk_iHd","executionInfo":{"status":"ok","timestamp":1721157704144,"user_tz":240,"elapsed":181,"user":{"displayName":"Liam Davies","userId":"11304128203820935965"}},"outputId":"04067e69-3fb4-40cb-dc5f-96959425ada5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["appName: Unknown_UDP totalSourceBytes: [NUM] totalDestinationBytes: [NUM] totalSourcePackets: [NUM] direction: L2R source: 192.168.2.107 protocolName: udp_ip sourcePort: [NUM] destination: 24.62.239.208 destinationPort: [NUM] year: [NUM] month: June day: [NUM] weekday: Sunday dayofyear: [NUM] hour: [NUM] minute: [NUM] second: [NUM] duration_seconds: [NUM]\n","389.0\n"]}]},{"cell_type":"code","source":["print(len(processed_texts))\n","print(len(y))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rJNVuU1qAlXI","executionInfo":{"status":"ok","timestamp":1721158262679,"user_tz":240,"elapsed":187,"user":{"displayName":"Liam Davies","userId":"11304128203820935965"}},"outputId":"aa7be0f8-2433-453d-96c6-62b28597fd2f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1746630\n","1746630\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from transformers import AutoTokenizer\n","\n","\n","# Convert processed_text and y into pandas DataFrames\n","processed_text = pd.DataFrame({'text': x_textual})\n","labels = pd.DataFrame(y)\n","\n","# Reset indices to ensure alignment\n","processed_text.reset_index(drop=True, inplace=True)\n","labels.reset_index(drop=True, inplace=True)\n","\n","print(processed_text.shape)\n","print(labels.shape)\n","\n","# Concatenate processed_text and y into a single DataFrame\n","data_ready = pd.concat([processed_text, labels], axis=1)\n","\n","\n","# Rename columns to \"text\" and \"label\"\n","data_ready.columns = [\"text\", \"label\"]\n","\n","print(data_ready.head())\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wR4m03Onbl79","executionInfo":{"status":"ok","timestamp":1721574395593,"user_tz":240,"elapsed":4574,"user":{"displayName":"Liam Davies","userId":"11304128203820935965"}},"outputId":"caf2bf81-2733-438a-cbdb-30d66fde51f4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(1746630, 1)\n","(1746630, 1)\n","                                                text  label\n","0  appName: HTTPImageTransfer totalSourceBytes: -...      0\n","1  appName: HTTPImageTransfer totalSourceBytes: -...      0\n","2  appName: Unknown_UDP totalSourceBytes: -0.0028...      0\n","3  appName: DNS totalSourceBytes: -0.003100816308...      0\n","4  appName: DNS totalSourceBytes: -0.002576579650...      0\n"]}]},{"cell_type":"code","source":["from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","import numpy as np\n","\n","# Define parameters\n","vocab_size = 20000\n","sequence_length = 600\n","\n","# Initialize and fit the tokenizer\n","tokenizer = Tokenizer(num_words=vocab_size)\n","tokenizer.fit_on_texts(processed_texts)\n","\n","# Convert text to sequences\n","sequences = tokenizer.texts_to_sequences(processed_texts)\n","\n","# Pad the sequences to ensure they are all the same length\n","padded_sequences = pad_sequences(sequences, maxlen=sequence_length, padding='post')\n","\n","# Normalize numeric values to fit within the embedding range (e.g., 0 to 1)\n","numeric_values = np.array(numeric_values)\n","numeric_values = (numeric_values - numeric_values.min()) / (numeric_values.max() - numeric_values.min())\n","\n","# Pad numeric values to match the sequence length\n","padded_numeric_values = pad_sequences([numeric_values], maxlen=sequence_length, padding='post')[0]\n","\n","# Split the data into training and test sets\n","x_train_text, x_test_text, y_train, y_test = train_test_split(padded_sequences, data_ready['label'], test_size=0.2, random_state=42)\n","x_train_num, x_test_num = train_test_split(padded_numeric_values, test_size=0.2, random_state=42)\n","\n","# Further split the training data into training and validation sets\n","x_train_text, x_val_text, y_train, y_val = train_test_split(x_train_text, y_train, test_size=0.2, random_state=42)\n","x_train_num, x_val_num = train_test_split(x_train_num, test_size=0.2, random_state=42)\n","\n","# Create TensorFlow Dataset objects\n","train_dataset = tf.data.Dataset.from_tensor_slices(((x_train_text, x_train_num), y_train)).batch(32)\n","val_dataset = tf.data.Dataset.from_tensor_slices(((x_val_text, x_val_num), y_val)).batch(32)\n","test_dataset = tf.data.Dataset.from_tensor_slices(((x_test_text, x_test_num), y_test)).batch(32)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":373},"id":"HdRtK1v0DBkk","executionInfo":{"status":"error","timestamp":1721158725351,"user_tz":240,"elapsed":114038,"user":{"displayName":"Liam Davies","userId":"11304128203820935965"}},"outputId":"e632336c-7135-4eed-da9f-507f00661a34"},"execution_count":null,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"Dimensions 1117843 and 384 are not compatible","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-17-e7bad81fc1e5>\u001b[0m in \u001b[0;36m<cell line: 35>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;31m# Create TensorFlow Dataset objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_tensor_slices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0mval_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_tensor_slices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_val_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0mtest_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_tensor_slices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mfrom_tensor_slices\u001b[0;34m(tensors, name)\u001b[0m\n\u001b[1;32m    823\u001b[0m     \u001b[0;31m# pylint: disable=g-import-not-at-top,protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfrom_tensor_slices_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfrom_tensor_slices_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_from_tensor_slices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    826\u001b[0m     \u001b[0;31m# pylint: enable=g-import-not-at-top,protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/from_tensor_slices_op.py\u001b[0m in \u001b[0;36m_from_tensor_slices\u001b[0;34m(tensors, name)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_from_tensor_slices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_TensorSliceDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/from_tensor_slices_op.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, element, is_files, name)\u001b[0m\n\u001b[1;32m     43\u001b[0m         tensor_shape.dimension_value(self._tensors[0].get_shape()[0]))\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tensors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m       batch_dim.assert_is_compatible_with(\n\u001b[0m\u001b[1;32m     46\u001b[0m           tensor_shape.Dimension(\n\u001b[1;32m     47\u001b[0m               tensor_shape.dimension_value(t.get_shape()[0])))\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36massert_is_compatible_with\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    301\u001b[0m     \"\"\"\n\u001b[1;32m    302\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 303\u001b[0;31m       raise ValueError(\"Dimensions %s and %s are not compatible\" %\n\u001b[0m\u001b[1;32m    304\u001b[0m                        (self, other))\n\u001b[1;32m    305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Dimensions 1117843 and 384 are not compatible"]}]},{"cell_type":"code","source":[],"metadata":{"id":"lAFs8vSWDBh4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"ZgnjPpixDBfl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"9eCDpr7cDBdK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"-RaCYYW6DBaw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"4meJIYNgDBYF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"z04n6gW3DBVi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"OjIR42wNDBSv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","\n","# Define parameters\n","vocab_size = 17733\n","sequence_length = 50\n","\n","# Initialize and fit the tokenizer\n","tokenizer = Tokenizer(num_words=vocab_size)\n","tokenizer.fit_on_texts(data_ready['text'])\n","\n","# Convert text to sequences\n","sequences = tokenizer.texts_to_sequences(data_ready['text'])\n","\n","# Pad the sequences to ensure they are all the same length\n","padded_sequences = pad_sequences(sequences, maxlen=sequence_length, padding='post')\n"],"metadata":{"id":"Otn84gHlDBPt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","# Get the word counts\n","word_counts = tokenizer.word_counts\n","sorted_word_counts = sorted(word_counts.items(), key=lambda item: item[1], reverse=True)\n","total_counts = sum(word_counts.values())\n","\n","# Calculate cumulative coverage\n","cumulative_coverage = 0\n","coverage_threshold = 0.99\n","vocab_size_optimal = 0\n","for i, (word, count) in enumerate(sorted_word_counts):\n","    cumulative_coverage += count / total_counts\n","    if cumulative_coverage >= coverage_threshold:\n","        vocab_size_optimal = i + 1\n","        break\n","\n","print(f\"Optimal vocab size for {coverage_threshold*100}% coverage: {vocab_size_optimal}\")\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HwHFL5C91Urp","executionInfo":{"status":"ok","timestamp":1721574999151,"user_tz":240,"elapsed":413,"user":{"displayName":"Liam Davies","userId":"11304128203820935965"}},"outputId":"ba2b70cb-43b7-4381-efd4-b2b8b3092295"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Optimal vocab size for 99.0% coverage: 17733\n"]}]},{"cell_type":"code","source":["# Analyze sequence lengths\n","sequence_lengths = [len(seq) for seq in sequences]\n","plt.hist(sequence_lengths, bins=50)\n","plt.xlabel('Sequence Length')\n","plt.ylabel('Frequency')\n","plt.title('Sequence Length Distribution')\n","plt.show()\n","\n","# Choose optimal sequence length\n","sequence_length_optimal = int(np.percentile(sequence_lengths, 95))\n","print(f\"Optimal sequence length to cover 95% of data: {sequence_length_optimal}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":490},"id":"8ON77hh31Vg2","executionInfo":{"status":"ok","timestamp":1721575007312,"user_tz":240,"elapsed":4682,"user":{"displayName":"Liam Davies","userId":"11304128203820935965"}},"outputId":"3c13bbab-0945-47f6-ef81-741c533e7575"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Optimal sequence length to cover 95% of data: 50\n"]}]},{"cell_type":"code","source":["\n","from sklearn.model_selection import train_test_split\n","import tensorflow as tf\n","\n","# Split the data into training and test sets\n","x_train, x_test, y_train, y_test = train_test_split(padded_sequences, data_ready['label'], test_size=0.2, random_state=42)\n","\n","# Further split the training data into training and validation sets\n","x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n","\n","# Create TensorFlow Dataset objects\n","train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(32)\n","val_dataset = tf.data.Dataset.from_tensor_slices((x_val, y_val)).batch(32)\n","test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(32)\n"],"metadata":{"id":"uFWb-2RdeRRB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","import tensorflow as tf\n","\n","# Split the data into training and test sets\n","x_train, x_test, y_train, y_test = train_test_split(padded_sequences, data_ready['label'], test_size=0.2, random_state=42)\n","\n","# Further split the training data into training and validation sets\n","x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n","\n","# Create TensorFlow Dataset objects\n","train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(32)\n","val_dataset = tf.data.Dataset.from_tensor_slices((x_val, y_val)).batch(32)\n","test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(32)"],"metadata":{"id":"643hMfmKesSi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","\n","\n","# Define the custom PositionalEmbedding layer\n","class PositionalEmbedding(layers.Layer):\n","    def __init__(self, sequence_length, input_dim, output_dim, **kwargs):\n","        super().__init__(**kwargs)\n","        self.token_embeddings = layers.Embedding(input_dim=input_dim, output_dim=output_dim)\n","        self.position_embeddings = layers.Embedding(input_dim=sequence_length, output_dim=output_dim)\n","        self.sequence_length = sequence_length\n","        self.input_dim = input_dim\n","        self.output_dim = output_dim\n","\n","    def call(self, inputs):\n","        length = tf.shape(inputs)[-1]\n","        positions = tf.range(start=0, limit=length, delta=1)\n","        embedded_tokens = self.token_embeddings(inputs)\n","        embedded_positions = self.position_embeddings(positions)\n","        return embedded_tokens + embedded_positions\n","\n","    def compute_mask(self, inputs, mask=None):\n","        return tf.math.not_equal(inputs, 0)\n","\n","    def get_config(self):\n","        config = super().get_config()\n","        config.update({\n","            \"output_dim\": self.output_dim,\n","            \"sequence_length\": self.sequence_length,\n","            \"input_dim\": self.input_dim,\n","        })\n","        return config\n","\n","# Define the custom TransformerEncoder layer\n","class TransformerEncoder(layers.Layer):\n","    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n","        super().__init__(**kwargs)\n","        self.embed_dim = embed_dim\n","        self.dense_dim = dense_dim\n","        self.num_heads = num_heads\n","        self.attention = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n","        self.dense_proj = keras.Sequential([layers.Dense(dense_dim, activation=\"relu\"), layers.Dense(embed_dim)])\n","        self.layernorm_1 = layers.LayerNormalization()\n","        self.layernorm_2 = layers.LayerNormalization()\n","\n","    def call(self, inputs, mask=None):\n","        if mask is not None:\n","            mask = mask[:, tf.newaxis, :]\n","        attention_output = self.attention(inputs, inputs, attention_mask=mask)\n","        proj_input = self.layernorm_1(inputs + attention_output)\n","        proj_output = self.dense_proj(proj_input)\n","        return self.layernorm_2(proj_input + proj_output)\n","\n","    def get_config(self):\n","        config = super().get_config()\n","        config.update({\n","            \"embed_dim\": self.embed_dim,\n","            \"num_heads\": self.num_heads,\n","            \"dense_dim\": self.dense_dim,\n","        })\n","        return config\n","\n","# Define model parameters\n","embed_dim = 256\n","num_heads = 2\n","dense_dim = 32\n","\n","# Build the model\n","inputs = keras.Input(shape=(None,), dtype=\"int64\")\n","x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(inputs)\n","x = TransformerEncoder(embed_dim, dense_dim, num_heads)(x)\n","x = layers.GlobalMaxPooling1D()(x)\n","x = layers.Dropout(0.5)(x)\n","outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n","model = keras.Model(inputs, outputs)\n","\n","model.compile(optimizer=\"rmsprop\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n","\n","model.summary()\n","\n","# Train the model\n","#callbacks = [keras.callbacks.ModelCheckpoint(\"transformer_encoder.keras\", save_best_only=True)]\n","\n","callbacks = [\n","    keras.callbacks.ModelCheckpoint(\"transformer_encoder.keras\", save_best_only=True),\n","    keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n","]\n","\n","\n","\n","model.fit(train_dataset, validation_data=val_dataset, epochs=20, callbacks=callbacks)\n","\n","# Load the best model and evaluate\n","model = keras.models.load_model(\"transformer_encoder.keras\", custom_objects={\"TransformerEncoder\": TransformerEncoder, \"PositionalEmbedding\": PositionalEmbedding})\n","\n","\n","print(f\"Test accuracy: {model.evaluate(test_dataset)[1]:.3f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4c4rB2hmfF33","executionInfo":{"status":"ok","timestamp":1721578135367,"user_tz":240,"elapsed":2919567,"user":{"displayName":"Liam Davies","userId":"11304128203820935965"}},"outputId":"8f0c126d-5dfa-4aad-ceb6-6c70ff222914"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, None)]            0         \n","                                                                 \n"," positional_embedding (Posi  (None, None, 256)         4552448   \n"," tionalEmbedding)                                                \n","                                                                 \n"," transformer_encoder (Trans  (None, None, 256)         543776    \n"," formerEncoder)                                                  \n","                                                                 \n"," global_max_pooling1d (Glob  (None, 256)               0         \n"," alMaxPooling1D)                                                 \n","                                                                 \n"," dropout (Dropout)           (None, 256)               0         \n","                                                                 \n"," dense_2 (Dense)             (None, 1)                 257       \n","                                                                 \n","=================================================================\n","Total params: 5096481 (19.44 MB)\n","Trainable params: 5096481 (19.44 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","Epoch 1/20\n","34933/34933 [==============================] - 315s 9ms/step - loss: 0.0043 - accuracy: 0.9990 - val_loss: 0.0016 - val_accuracy: 0.9997\n","Epoch 2/20\n","34933/34933 [==============================] - 320s 9ms/step - loss: 0.0023 - accuracy: 0.9995 - val_loss: 0.0017 - val_accuracy: 0.9997\n","Epoch 3/20\n","34933/34933 [==============================] - 318s 9ms/step - loss: 0.0019 - accuracy: 0.9996 - val_loss: 8.5852e-04 - val_accuracy: 0.9998\n","Epoch 4/20\n","34933/34933 [==============================] - 315s 9ms/step - loss: 0.0016 - accuracy: 0.9997 - val_loss: 8.7037e-04 - val_accuracy: 0.9998\n","Epoch 5/20\n","34933/34933 [==============================] - 319s 9ms/step - loss: 0.0014 - accuracy: 0.9997 - val_loss: 8.3330e-04 - val_accuracy: 0.9998\n","Epoch 6/20\n","34933/34933 [==============================] - 317s 9ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 7.2442e-04 - val_accuracy: 0.9998\n","Epoch 7/20\n","34933/34933 [==============================] - 317s 9ms/step - loss: 0.0010 - accuracy: 0.9998 - val_loss: 8.0830e-04 - val_accuracy: 0.9999\n","Epoch 8/20\n","34933/34933 [==============================] - 318s 9ms/step - loss: 8.6010e-04 - accuracy: 0.9998 - val_loss: 7.3381e-04 - val_accuracy: 0.9999\n","Epoch 9/20\n","34933/34933 [==============================] - 317s 9ms/step - loss: 7.2760e-04 - accuracy: 0.9999 - val_loss: 0.0011 - val_accuracy: 0.9998\n","10917/10917 [==============================] - 58s 5ms/step - loss: 8.1443e-04 - accuracy: 0.9999\n","Test accuracy: 1.000\n"]}]},{"cell_type":"code","source":["# Generate predictions for the test set\n","predictions = model.predict(test_dataset)\n","# Convert probabilities to binary predictions\n","binary_predictions = (predictions > 0.5).astype(int)\n","# Assuming you have the true labels stored in `test_labels`\n","from sklearn.metrics import classification_report\n","print(classification_report(y_test, binary_predictions))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tpp5SDc6iqXb","executionInfo":{"status":"ok","timestamp":1721578869828,"user_tz":240,"elapsed":56466,"user":{"displayName":"Liam Davies","userId":"11304128203820935965"}},"outputId":"d09c8e93-3a63-4659-fe0d-8102da64e2b9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["10917/10917 [==============================] - 49s 4ms/step\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00    337617\n","           1       1.00      1.00      1.00     11709\n","\n","    accuracy                           1.00    349326\n","   macro avg       1.00      1.00      1.00    349326\n","weighted avg       1.00      1.00      1.00    349326\n","\n"]}]}]}